# SeaweedFS-Up Deployment Examples

This document provides real-world deployment examples and practical scenarios for using SeaweedFS-up in production environments.

## üìö Table of Contents

- [üöÄ Quick Development Setup](#quick-development-setup)
- [üè¢ Production Deployment](#production-deployment)
- [üîí Secure Enterprise Deployment](#secure-enterprise-deployment)
- [‚òÅÔ∏è Multi-Cloud Deployment](#multi-cloud-deployment)
- [üîÑ CI/CD Integration](#cicd-integration)
- [üìä Monitoring-First Deployment](#monitoring-first-deployment)
- [‚ö° High-Performance Setup](#high-performance-setup)
- [üåç Global Distributed Setup](#global-distributed-setup)

---

## üöÄ Quick Development Setup

**Scenario:** Developer wants to quickly spin up a SeaweedFS cluster for local development and testing.

### Step 1: Generate Development Template

```bash
# Generate a single-node development configuration
./seaweed-up template generate single-node \
  --output dev-cluster.yaml \
  --set cluster.name=dev-cluster \
  --set master.host=localhost \
  --set volume.host=localhost \
  --set filer.host=localhost
```

### Step 2: Deploy the Cluster

```bash
# Deploy locally (no SSH required)
./seaweed-up cluster deploy -f dev-cluster.yaml --local

# Check status
./seaweed-up cluster status dev-cluster
```

### Expected Configuration

```yaml
cluster_name: "dev-cluster"

global:
  enable_tls: false
  dir:
    conf: "/tmp/seaweed-dev/conf"
    data: "/tmp/seaweed-dev/data"
  replication: "000"

master_servers:
  - ip: "localhost"
    port: 9333

volume_servers:
  - ip: "localhost"
    port: 8080
    masters: ["localhost:9333"]
    folders:
      - folder: "/tmp/seaweed-dev/data/volume1"

filer_servers:
  - ip: "localhost"
    port: 8888
    masters: ["localhost:9333"]
    s3: true
    s3_port: 8333
```

### Usage

```bash
# Test S3 API
aws --endpoint-url=http://localhost:8333 s3 mb s3://test-bucket

# Test Filer API
curl -X POST "http://localhost:8888/test-file" \
  --data-binary @README.md
```

---

## üè¢ Production Deployment

**Scenario:** Deploy a production-ready SeaweedFS cluster across multiple dedicated servers with high availability.

### Architecture Overview

```
Production Cluster:
‚îú‚îÄ‚îÄ Masters (HA): 3 nodes
‚îú‚îÄ‚îÄ Volume Servers: 6 nodes  
‚îú‚îÄ‚îÄ Filer Servers (HA): 2 nodes
‚îî‚îÄ‚îÄ Envoy Proxies: 2 nodes (Load Balancing)
```

### Step 1: Generate Production Template

```bash
./seaweed-up template generate production \
  --output prod-cluster.yaml \
  --set cluster.name=prod-seaweed \
  --set master.replication=001 \
  --set volume.max_volumes=200 \
  --set monitoring.enabled=true
```

### Step 2: Customize Configuration

```yaml
cluster_name: "prod-seaweed"

global:
  enable_tls: true
  dir:
    conf: "/opt/seaweed/conf"
    data: "/opt/seaweed/data"
  replication: "001"
  volumeSizeLimitMB: 10000

# High-availability master servers
master_servers:
  - ip: "10.10.1.10"
    port: 9333
    peers: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
  - ip: "10.10.1.11"
    port: 9333
    peers: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
  - ip: "10.10.1.12"
    port: 9333
    peers: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]

# Volume servers with multiple disks
volume_servers:
  - ip: "10.10.2.10"
    port: 8080
    masters: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
    max_volumes: 200
    folders:
      - folder: "/data1/seaweed"
        disk: "ssd"
      - folder: "/data2/seaweed"
        disk: "ssd"
  - ip: "10.10.2.11"
    port: 8080
    masters: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
    max_volumes: 200
    folders:
      - folder: "/data1/seaweed"
        disk: "ssd"
      - folder: "/data2/seaweed"
        disk: "ssd"
  - ip: "10.10.2.12"
    port: 8080
    masters: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
    max_volumes: 200
    folders:
      - folder: "/data1/seaweed"
        disk: "ssd"
      - folder: "/data2/seaweed"
        disk: "ssd"
  - ip: "10.10.2.13"
    port: 8080
    masters: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
    max_volumes: 200
    folders:
      - folder: "/data1/seaweed"
        disk: "hdd"
      - folder: "/data2/seaweed"
        disk: "hdd"
  - ip: "10.10.2.14"
    port: 8080
    masters: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
    max_volumes: 200
    folders:
      - folder: "/data1/seaweed"
        disk: "hdd"
      - folder: "/data2/seaweed" 
        disk: "hdd"
  - ip: "10.10.2.15"
    port: 8080
    masters: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
    max_volumes: 200
    folders:
      - folder: "/data1/seaweed"
        disk: "hdd"
      - folder: "/data2/seaweed"
        disk: "hdd"

# Filer servers for S3 and WebDAV
filer_servers:
  - ip: "10.10.3.10"
    port: 8888
    masters: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
    s3: true
    s3_port: 8333
    webdav: true
    webdav_port: 7333
  - ip: "10.10.3.11"
    port: 8888
    masters: ["10.10.1.10:9333", "10.10.1.11:9333", "10.10.1.12:9333"]
    s3: true
    s3_port: 8333
    webdav: true
    webdav_port: 7333

# Load balancer proxies
envoy_servers:
  - ip: "10.10.4.10"
    port: 8000
    targets: ["10.10.3.10:8888", "10.10.3.11:8888"]
  - ip: "10.10.4.11"
    port: 8000
    targets: ["10.10.3.10:8888", "10.10.3.11:8888"]
```

### Step 3: Deploy with Security

```bash
# Initialize TLS certificates
./seaweed-up security tls init prod-seaweed \
  --organization="My Company" \
  --country=US \
  --validity=5

# Generate certificates for all components
./seaweed-up security tls generate -f prod-cluster.yaml

# Initialize JWT authentication
./seaweed-up security auth init prod-seaweed --method=jwt

# Deploy the cluster
./seaweed-up cluster deploy -f prod-cluster.yaml \
  --user=seaweed \
  --identity-file=~/.ssh/seaweed-prod-key \
  --tls

# Verify deployment
./seaweed-up cluster status prod-seaweed --detailed
```

### Step 4: Set Up Monitoring

```bash
# Start metrics collection
./seaweed-up monitoring metrics start prod-seaweed

# Create production alerts
./seaweed-up monitoring alerts create \
  --name=disk-usage-high \
  --metric=disk_usage \
  --condition=">85" \
  --severity=warning \
  --summary="High disk usage on {{.Host}}: {{.Value}}%"

./seaweed-up monitoring alerts create \
  --name=volume-server-down \
  --metric=component_health \
  --condition="==0" \
  --severity=critical \
  --summary="Volume server down: {{.Host}}"
```

---

## üîí Secure Enterprise Deployment

**Scenario:** Deploy SeaweedFS in a highly secure enterprise environment with strict compliance requirements.

### Security Requirements

- ‚úÖ End-to-end TLS encryption
- ‚úÖ Mutual TLS authentication
- ‚úÖ Role-based access control
- ‚úÖ Audit logging
- ‚úÖ Certificate rotation
- ‚úÖ Network segmentation

### Step 1: Security-First Template

```bash
./seaweed-up template generate high-availability \
  --output secure-cluster.yaml \
  --set cluster.name=secure-enterprise \
  --set security.tls=true \
  --set security.mtls=true \
  --set monitoring.audit=true
```

### Step 2: Advanced TLS Configuration

```bash
# Initialize CA with enterprise settings
./seaweed-up security tls init secure-enterprise \
  --organization="Enterprise Corp" \
  --country=US \
  --validity=3 \
  --key-size=4096

# Generate certificates with extended validation
./seaweed-up security tls generate -f secure-cluster.yaml \
  --san="seaweed.enterprise.com,*.seaweed.enterprise.com" \
  --extended-key-usage="serverAuth,clientAuth,codeSigning"
```

### Step 3: Mutual TLS Authentication

```bash
# Initialize mTLS authentication
./seaweed-up security auth init secure-enterprise --method=mtls

# Create client certificates for authorized users
./seaweed-up security tls client-cert admin \
  --cn="admin@enterprise.com" \
  --org="Enterprise Corp" \
  --permissions="read,write,admin"

./seaweed-up security tls client-cert readonly \
  --cn="reader@enterprise.com" \
  --org="Enterprise Corp" \
  --permissions="read"
```

### Step 4: Enhanced Cluster Configuration

```yaml
cluster_name: "secure-enterprise"

global:
  enable_tls: true
  mtls_enabled: true
  dir:
    conf: "/opt/seaweed/conf"
    data: "/opt/seaweed/data"
  replication: "001"
  audit_logging: true

server_configs:
  master_server:
    tls_cert: "/opt/seaweed/certs/master-cert.pem"
    tls_key: "/opt/seaweed/certs/master-key.pem"
    ca_cert: "/opt/seaweed/certs/ca-cert.pem"
    verify_client_cert: true
    
  volume_server:
    tls_cert: "/opt/seaweed/certs/volume-cert.pem"
    tls_key: "/opt/seaweed/certs/volume-key.pem"
    ca_cert: "/opt/seaweed/certs/ca-cert.pem"
    
  filer_server:
    tls_cert: "/opt/seaweed/certs/filer-cert.pem"
    tls_key: "/opt/seaweed/certs/filer-key.pem"
    ca_cert: "/opt/seaweed/certs/ca-cert.pem"
    jwt_secret_file: "/opt/seaweed/conf/jwt-secret"

# Network-segmented deployment
master_servers:
  - ip: "10.1.1.10"    # Management network
    port: 9333
  - ip: "10.1.1.11"
    port: 9333
  - ip: "10.1.1.12"
    port: 9333

volume_servers:
  - ip: "10.1.2.10"    # Storage network
    port: 8080
  - ip: "10.1.2.11"
    port: 8080
  - ip: "10.1.2.12"
    port: 8080

filer_servers:
  - ip: "10.1.3.10"    # Application network
    port: 8888
    s3: true
    s3_port: 8333
```

### Step 5: Security Hardening

```bash
# Apply security hardening
./seaweed-up security harden -f secure-cluster.yaml

# Deploy with maximum security
./seaweed-up cluster deploy -f secure-cluster.yaml \
  --user=seaweed \
  --identity-file=~/.ssh/enterprise-key \
  --tls \
  --verify-certificates \
  --strict-host-checking

# Perform security audit
./seaweed-up security audit --compliance=SOC2
```

---

## ‚òÅÔ∏è Multi-Cloud Deployment

**Scenario:** Deploy SeaweedFS across multiple cloud providers for disaster recovery and data locality.

### Architecture

```
Multi-Cloud Setup:
‚îú‚îÄ‚îÄ AWS Region (us-east-1)
‚îÇ   ‚îú‚îÄ‚îÄ Masters: 2 nodes
‚îÇ   ‚îú‚îÄ‚îÄ Volume Servers: 4 nodes
‚îÇ   ‚îî‚îÄ‚îÄ Filers: 1 node
‚îú‚îÄ‚îÄ GCP Region (us-central1)
‚îÇ   ‚îú‚îÄ‚îÄ Masters: 1 node
‚îÇ   ‚îú‚îÄ‚îÄ Volume Servers: 4 nodes
‚îÇ   ‚îî‚îÄ‚îÄ Filers: 1 node
‚îî‚îÄ‚îÄ Cross-cloud replication: 002
```

### AWS Configuration

```yaml
# aws-cluster.yaml
cluster_name: "multi-cloud-aws"

global:
  enable_tls: true
  replication: "002"
  cross_region_replication: true

master_servers:
  - ip: "10.0.1.10"    # AWS private IP
    public_ip: "54.1.1.10"
    port: 9333
    region: "us-east-1"
    availability_zone: "us-east-1a"
  - ip: "10.0.1.11"
    public_ip: "54.1.1.11"
    port: 9333
    region: "us-east-1"
    availability_zone: "us-east-1b"

volume_servers:
  - ip: "10.0.2.10"
    region: "us-east-1"
    availability_zone: "us-east-1a"
    folders:
      - folder: "/data/hot"
        disk_type: "gp3"
      - folder: "/data/warm"
        disk_type: "st1"
```

### GCP Configuration

```yaml
# gcp-cluster.yaml  
cluster_name: "multi-cloud-gcp"

global:
  enable_tls: true
  replication: "002"
  cross_region_replication: true

master_servers:
  - ip: "10.1.1.10"    # GCP private IP
    public_ip: "35.1.1.10"
    port: 9333
    region: "us-central1"
    zone: "us-central1-a"

volume_servers:
  - ip: "10.1.2.10"
    region: "us-central1"
    zone: "us-central1-a"
    folders:
      - folder: "/data/hot"
        disk_type: "pd-ssd"
      - folder: "/data/warm"
        disk_type: "pd-standard"
```

### Deployment Commands

```bash
# Deploy AWS cluster
./seaweed-up cluster deploy -f aws-cluster.yaml \
  --user=ubuntu \
  --identity-file=~/.ssh/aws-key.pem \
  --region=us-east-1

# Deploy GCP cluster
./seaweed-up cluster deploy -f gcp-cluster.yaml \
  --user=seaweed \
  --identity-file=~/.ssh/gcp-key \
  --region=us-central1

# Configure cross-cloud replication
./seaweed-up cluster link \
  --primary=multi-cloud-aws \
  --secondary=multi-cloud-gcp \
  --replication-strategy=async
```

---

## üîÑ CI/CD Integration

**Scenario:** Integrate SeaweedFS-up deployments into CI/CD pipelines with automated testing and rollbacks.

### GitLab CI Example

```yaml
# .gitlab-ci.yml
stages:
  - validate
  - deploy-staging  
  - test
  - deploy-production
  - monitor

variables:
  SEAWEED_UP_VERSION: "2.0.0"
  
before_script:
  - curl -L -o seaweed-up "https://github.com/seaweedfs/seaweed-up/releases/download/v${SEAWEED_UP_VERSION}/seaweed-up-linux-amd64"
  - chmod +x seaweed-up
  - ./seaweed-up env init

validate-config:
  stage: validate
  script:
    - ./seaweed-up template validate cluster-staging.yaml
    - ./seaweed-up template validate cluster-production.yaml
    - ./seaweed-up security audit --config-only
  rules:
    - changes:
        - "cluster-*.yaml"

deploy-staging:
  stage: deploy-staging
  script:
    - ./seaweed-up cluster deploy -f cluster-staging.yaml --dry-run
    - ./seaweed-up cluster deploy -f cluster-staging.yaml --wait-for-ready
    - ./seaweed-up cluster status staging-cluster --detailed
  environment:
    name: staging
    url: http://staging.seaweed.company.com
  rules:
    - if: '$CI_COMMIT_BRANCH == "develop"'

integration-tests:
  stage: test
  script:
    - ./scripts/run-integration-tests.sh staging-cluster
    - ./seaweed-up monitoring metrics query --cluster=staging-cluster --health-check
  dependencies:
    - deploy-staging

deploy-production:
  stage: deploy-production
  script:
    - ./seaweed-up cluster upgrade production-cluster --version=$NEW_VERSION --staged
    - ./seaweed-up cluster status production-cluster --wait-for-healthy
  environment:
    name: production
    url: http://seaweed.company.com
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
  when: manual

monitor-deployment:
  stage: monitor
  script:
    - ./seaweed-up monitoring alerts create --name=deployment-health
    - sleep 300  # Monitor for 5 minutes
    - ./seaweed-up monitoring alerts list --active
  dependencies:
    - deploy-production
```

### GitHub Actions Example

```yaml
# .github/workflows/deploy.yml
name: SeaweedFS Deployment

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Download seaweed-up
        run: |
          curl -L -o seaweed-up "https://github.com/seaweedfs/seaweed-up/releases/download/v2.0.0/seaweed-up-linux-amd64"
          chmod +x seaweed-up
          
      - name: Validate configurations
        run: |
          ./seaweed-up template validate cluster-staging.yaml
          ./seaweed-up security audit --config-only

  deploy-staging:
    needs: validate
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.7.0
        with:
          ssh-private-key: ${{ secrets.STAGING_SSH_KEY }}
          
      - name: Deploy to staging
        run: |
          ./seaweed-up cluster deploy -f cluster-staging.yaml
          ./seaweed-up cluster status staging-cluster --wait-for-ready
          
  deploy-production:
    needs: validate
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - name: Deploy with blue-green strategy
        run: |
          ./seaweed-up cluster deploy -f cluster-production.yaml --strategy=blue-green
          ./seaweed-up cluster switchover production-cluster --verify-health
```

---

## üìä Monitoring-First Deployment

**Scenario:** Deploy SeaweedFS with comprehensive monitoring, alerting, and observability from day one.

### Step 1: Monitoring-Enhanced Template

```yaml
cluster_name: "monitored-cluster"

global:
  enable_tls: true
  monitoring:
    enabled: true
    metrics_port: 9090
    health_check_interval: "30s"

# Monitoring configuration embedded in template
monitoring:
  metrics:
    enabled: true
    collection_interval: "15s"
    retention: "30d"
    storage_path: "/opt/monitoring/metrics"
    
  alerting:
    enabled: true
    rules:
      - name: "master-server-down"
        metric: "component_health"
        component: "master"
        condition: "==0"
        severity: "critical"
        summary: "Master server down: {{.Host}}"
        
      - name: "high-disk-usage"
        metric: "disk_usage_percent"
        condition: ">85"
        severity: "warning"
        summary: "High disk usage on {{.Host}}: {{.Value}}%"
        
      - name: "volume-server-memory"
        metric: "memory_usage_percent"
        component: "volume"
        condition: ">90"
        severity: "critical"
        summary: "Critical memory usage on volume server {{.Host}}"
        
    notifiers:
      - type: "slack"
        name: "ops-alerts"
        config:
          webhook_url: "${SLACK_WEBHOOK_URL}"
          channel: "#seaweedfs-alerts"
          
      - type: "email"
        name: "ops-email"
        config:
          smtp_host: "smtp.company.com"
          smtp_port: 587
          from: "seaweed-alerts@company.com"
          to: ["ops-team@company.com"]
```

### Step 2: Deploy with Monitoring

```bash
# Deploy with monitoring enabled
export SLACK_WEBHOOK_URL="https://hooks.slack.com/services/..."

./seaweed-up cluster deploy -f monitored-cluster.yaml \
  --enable-monitoring \
  --metrics-retention=30d

# Start monitoring immediately
./seaweed-up monitoring metrics start monitored-cluster

# Launch dashboard
./seaweed-up monitoring dashboard monitored-cluster &
```

### Step 3: Custom Monitoring Integration

```bash
# Export metrics to external systems
./seaweed-up monitoring metrics export \
  --format=prometheus \
  --endpoint="http://prometheus.company.com:9090/api/v1/write"

# Set up log forwarding  
./seaweed-up cluster configure monitored-cluster \
  --log-forwarding="syslog://logstash.company.com:5514"

# Custom health checks
./seaweed-up monitoring health-check create \
  --name="s3-api-check" \
  --type="http" \
  --endpoint="https://s3.seaweed.company.com/health" \
  --interval="60s"
```

---

## ‚ö° High-Performance Setup

**Scenario:** Deploy SeaweedFS optimized for maximum performance with SSD storage and network optimization.

### Performance-Optimized Configuration

```yaml
cluster_name: "high-perf-cluster"

global:
  enable_tls: true
  replication: "000"  # No replication for max performance
  volumeSizeLimitMB: 30000  # Large volumes
  
server_configs:
  master_server:
    concurrent_uploads: 64
    max_cpu: 16
    
  volume_server:
    max_volumes: 500
    io_timeout: "30s"
    concurrent_reads: 128
    concurrent_writes: 64
    compaction_mb_per_second: 50
    
  filer_server:
    memory_map_max_size_mb: 4096
    concurrent_upload_limit: 128

# High-performance volume servers
volume_servers:
  - ip: "10.0.1.10"
    port: 8080
    folders:
      - folder: "/nvme1/seaweed"
        disk: "nvme"
        max_volumes: 100
      - folder: "/nvme2/seaweed"
        disk: "nvme"
        max_volumes: 100
      - folder: "/nvme3/seaweed"
        disk: "nvme"  
        max_volumes: 100
      - folder: "/nvme4/seaweed"
        disk: "nvme"
        max_volumes: 100
      - folder: "/ssd1/seaweed"
        disk: "ssd"
        max_volumes: 100
    system_config:
      cpu_cores: 32
      memory_gb: 128
      network_bandwidth: "10Gbps"
```

### Performance Tuning Commands

```bash
# Deploy with performance optimizations
./seaweed-up cluster deploy -f high-perf-cluster.yaml \
  --tune-for-performance \
  --disable-debug-logging \
  --memory-map-enabled

# Performance monitoring
./seaweed-up monitoring metrics query \
  --metric=throughput_mbps \
  --metric=iops \
  --metric=latency_p99

# Benchmark the cluster
./seaweed-up cluster benchmark high-perf-cluster \
  --test-type=write \
  --file-size=1MB \
  --concurrent-clients=64 \
  --duration=300s
```

---

## üåç Global Distributed Setup

**Scenario:** Deploy SeaweedFS across multiple geographical regions with data locality optimization.

### Global Architecture

```
Global SeaweedFS:
‚îú‚îÄ‚îÄ US-East (Primary)
‚îÇ   ‚îú‚îÄ‚îÄ Masters: 2 nodes
‚îÇ   ‚îî‚îÄ‚îÄ Volume/Filer: 6 nodes
‚îú‚îÄ‚îÄ EU-West (Secondary)  
‚îÇ   ‚îú‚îÄ‚îÄ Masters: 1 node
‚îÇ   ‚îî‚îÄ‚îÄ Volume/Filer: 4 nodes
‚îú‚îÄ‚îÄ APAC-Southeast (Edge)
‚îÇ   ‚îî‚îÄ‚îÄ Volume/Filer: 2 nodes
‚îî‚îÄ‚îÄ Cross-region replication
```

### Region-Specific Configurations

```yaml
# us-east-cluster.yaml
cluster_name: "global-us-east"

global:
  region: "us-east-1"
  cross_region_replication: true
  data_center: "us-east"
  replication: "010"  # Cross-datacenter replication

master_servers:
  - ip: "10.100.1.10"
    port: 9333
    region: "us-east-1"
    data_center: "us-east"
    global_master: true
    peers: ["10.100.1.10:9333", "10.100.1.11:9333", "10.200.1.10:9333"]
    
volume_servers:
  - ip: "10.100.2.10"
    port: 8080
    region: "us-east-1"
    data_center: "us-east"
    tier: "hot"
    folders:
      - folder: "/data/hot-ssd"
        disk: "ssd"
        tier: "hot"
```

```yaml
# eu-west-cluster.yaml
cluster_name: "global-eu-west"

global:
  region: "eu-west-1"
  cross_region_replication: true
  data_center: "eu-west"
  replication: "010"

master_servers:
  - ip: "10.200.1.10"
    port: 9333
    region: "eu-west-1" 
    data_center: "eu-west"
    peers: ["10.100.1.10:9333", "10.100.1.11:9333", "10.200.1.10:9333"]

volume_servers:
  - ip: "10.200.2.10"
    port: 8080
    region: "eu-west-1"
    data_center: "eu-west"
    compliance: "GDPR"
    folders:
      - folder: "/data/eu-compliant"
        disk: "ssd"
        data_locality: "eu-only"
```

### Global Deployment Commands

```bash
# Deploy primary region
./seaweed-up cluster deploy -f us-east-cluster.yaml \
  --region=us-east-1 \
  --global-primary

# Deploy secondary regions  
./seaweed-up cluster deploy -f eu-west-cluster.yaml \
  --region=eu-west-1 \
  --connect-to-primary=global-us-east

# Deploy edge locations
./seaweed-up cluster deploy -f apac-edge-cluster.yaml \
  --region=ap-southeast-1 \
  --edge-cache-only \
  --connect-to-primary=global-us-east

# Configure global routing
./seaweed-up cluster configure-routing \
  --geo-routing \
  --primary-region=us-east-1 \
  --failover-region=eu-west-1
```

---

## üìã Summary

These deployment examples demonstrate SeaweedFS-up's versatility across different scenarios:

- **üöÄ Development**: Quick local setup for testing
- **üè¢ Production**: Enterprise-grade high-availability deployment
- **üîí Security**: Comprehensive security and compliance setup
- **‚òÅÔ∏è Multi-Cloud**: Cross-cloud deployment with disaster recovery
- **üîÑ CI/CD**: Automated pipeline integration
- **üìä Monitoring**: Observability-first deployment approach
- **‚ö° Performance**: Optimized for maximum throughput
- **üåç Global**: Worldwide distributed setup with data locality

Each example includes:
- ‚úÖ Complete configuration files
- ‚úÖ Step-by-step deployment commands
- ‚úÖ Security considerations
- ‚úÖ Monitoring setup
- ‚úÖ Performance optimizations
- ‚úÖ Troubleshooting guidance

Choose the example that best matches your use case and customize it for your specific requirements. SeaweedFS-up's modular architecture makes it easy to combine features from different examples to create your ideal deployment.

For more detailed configuration options, see the [User Guide](USER_GUIDE.md) and [Developer Guide](DEVELOPER_GUIDE.md).

---

*These examples are based on SeaweedFS-up v2.0.0. Always use the latest version for production deployments.*
